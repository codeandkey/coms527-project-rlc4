#pragma once

/*
 * MCTS implementation
 */

#include <vector>

#include "environment.h"

/**
 * Search node structure.
 */
struct Node {
    float w = 0.0f;         // Total value of node and children.
    int n = 0;              // Number of visits to this node.
    float p = 0.0f;         // Node prior probability.
    int action = -1;        // Action that led to this node (preceding edge label).
    int depth = 0;          // Depth of the subtree under this node.
    Node* parent = nullptr; // Pointer to parent, if there is one.
    std::vector<Node*> children; // List of child nodes.

    /**
     * Backpropagates a value up the tree.
     * 
     * @param v [in] Value to backprop.
     * @param depth [in] Current depth.
     */
    void backprop(float v, int depth = 0);

    /**
     * Gets the average value at this node.
     *
     * @return Average node value
     */
    float valueAverage();

    /**
     * Expands this node.
     * 
     * @param policy [in] Policy result
     * @param value [in] Value result
     */
    void expand(std::vector<int> actions, float* policy, float value);
};

class Tree {
    public:
        /**
         * Initializes a new environment and search tree.
         */
        Tree();

        /**
         * Cleans up a search tree and associated environment.
         */
        ~Tree();

        /**
         * Runs the next MCTS simulation. If a terminal is reached it is backpropagated immediately,
         * and the next simulation is returned. Returns NULL when no more selections are needed.
         * 
         * @return Next environment to expand, or NULL if node target reached.
         */
        Environment* simulate();

        /**
         * Returns the probability vector over next actions.
         * 
         * @return Vector of probabilities for each action.
         */
        std::vector<float> getProbabilities();

        /**
         * Returns the average value at the root node.
         * 
         * @return Average value at root node.
         */
        float valueAverage();

        /**
         * Samples an action from the probability vector generated by getProbabilities()
         * 
         * @return Selected action.
         */
        int chooseAction();

        /**
         * Expands the waiting node.
         * 
         * @param policy [in] Policy result
         * @param value [in] Value result
         */
        void expand(float* policy, float value);

        /**
         * Advances the tree. If subtrees are kept (MCTS_PRESERVE_SUBTREE) then the existing
         * subtree is kept. Otherwise, a new root is initialized.
         * 
         * @param action Action to take.
         */
        void advance(int action);
    private:
        Environment* env;
        Node* root, *target;
};
